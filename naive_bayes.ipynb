{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import json\n",
    "import pprint\n",
    "\n",
    "from scipy.io import arff\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_flag = arff.loadarff('./flags/flags-train.arff')\n",
    "train_df_flags = pd.DataFrame(data_flag[0])\n",
    "train_df_flags = train_df_flags.head(10)\n",
    "data_flag = arff.loadarff('./flags/flags-test.arff')\n",
    "test_df_flags = pd.DataFrame(data_flag[0])\n",
    "test_df_flags = test_df_flags.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>landmass</th>\n",
       "      <th>zone</th>\n",
       "      <th>language</th>\n",
       "      <th>religion</th>\n",
       "      <th>crescent</th>\n",
       "      <th>triangle</th>\n",
       "      <th>icon</th>\n",
       "      <th>animate</th>\n",
       "      <th>text</th>\n",
       "      <th>red</th>\n",
       "      <th>green</th>\n",
       "      <th>blue</th>\n",
       "      <th>yellow</th>\n",
       "      <th>white</th>\n",
       "      <th>black</th>\n",
       "      <th>orange</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>b'4'</td>\n",
       "      <td>b'1'</td>\n",
       "      <td>b'8'</td>\n",
       "      <td>b'2'</td>\n",
       "      <td>b'0'</td>\n",
       "      <td>b'0'</td>\n",
       "      <td>b'0'</td>\n",
       "      <td>b'1'</td>\n",
       "      <td>b'1'</td>\n",
       "      <td>b'1'</td>\n",
       "      <td>b'0'</td>\n",
       "      <td>b'0'</td>\n",
       "      <td>b'1'</td>\n",
       "      <td>b'1'</td>\n",
       "      <td>b'1'</td>\n",
       "      <td>b'0'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>b'2'</td>\n",
       "      <td>b'3'</td>\n",
       "      <td>b'2'</td>\n",
       "      <td>b'0'</td>\n",
       "      <td>b'0'</td>\n",
       "      <td>b'0'</td>\n",
       "      <td>b'0'</td>\n",
       "      <td>b'0'</td>\n",
       "      <td>b'0'</td>\n",
       "      <td>b'0'</td>\n",
       "      <td>b'0'</td>\n",
       "      <td>b'1'</td>\n",
       "      <td>b'1'</td>\n",
       "      <td>b'1'</td>\n",
       "      <td>b'0'</td>\n",
       "      <td>b'0'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>b'2'</td>\n",
       "      <td>b'4'</td>\n",
       "      <td>b'2'</td>\n",
       "      <td>b'0'</td>\n",
       "      <td>b'0'</td>\n",
       "      <td>b'0'</td>\n",
       "      <td>b'0'</td>\n",
       "      <td>b'0'</td>\n",
       "      <td>b'0'</td>\n",
       "      <td>b'1'</td>\n",
       "      <td>b'0'</td>\n",
       "      <td>b'1'</td>\n",
       "      <td>b'0'</td>\n",
       "      <td>b'1'</td>\n",
       "      <td>b'0'</td>\n",
       "      <td>b'0'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>b'6'</td>\n",
       "      <td>b'2'</td>\n",
       "      <td>b'1'</td>\n",
       "      <td>b'1'</td>\n",
       "      <td>b'0'</td>\n",
       "      <td>b'0'</td>\n",
       "      <td>b'0'</td>\n",
       "      <td>b'0'</td>\n",
       "      <td>b'0'</td>\n",
       "      <td>b'1'</td>\n",
       "      <td>b'0'</td>\n",
       "      <td>b'1'</td>\n",
       "      <td>b'1'</td>\n",
       "      <td>b'1'</td>\n",
       "      <td>b'0'</td>\n",
       "      <td>b'0'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>b'5'</td>\n",
       "      <td>b'1'</td>\n",
       "      <td>b'10'</td>\n",
       "      <td>b'3'</td>\n",
       "      <td>b'0'</td>\n",
       "      <td>b'0'</td>\n",
       "      <td>b'0'</td>\n",
       "      <td>b'1'</td>\n",
       "      <td>b'0'</td>\n",
       "      <td>b'1'</td>\n",
       "      <td>b'0'</td>\n",
       "      <td>b'0'</td>\n",
       "      <td>b'0'</td>\n",
       "      <td>b'1'</td>\n",
       "      <td>b'1'</td>\n",
       "      <td>b'1'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>b'1'</td>\n",
       "      <td>b'4'</td>\n",
       "      <td>b'1'</td>\n",
       "      <td>b'1'</td>\n",
       "      <td>b'0'</td>\n",
       "      <td>b'0'</td>\n",
       "      <td>b'1'</td>\n",
       "      <td>b'0'</td>\n",
       "      <td>b'0'</td>\n",
       "      <td>b'0'</td>\n",
       "      <td>b'0'</td>\n",
       "      <td>b'1'</td>\n",
       "      <td>b'1'</td>\n",
       "      <td>b'0'</td>\n",
       "      <td>b'1'</td>\n",
       "      <td>b'0'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>b'5'</td>\n",
       "      <td>b'1'</td>\n",
       "      <td>b'10'</td>\n",
       "      <td>b'6'</td>\n",
       "      <td>b'0'</td>\n",
       "      <td>b'0'</td>\n",
       "      <td>b'0'</td>\n",
       "      <td>b'0'</td>\n",
       "      <td>b'0'</td>\n",
       "      <td>b'1'</td>\n",
       "      <td>b'0'</td>\n",
       "      <td>b'1'</td>\n",
       "      <td>b'0'</td>\n",
       "      <td>b'1'</td>\n",
       "      <td>b'0'</td>\n",
       "      <td>b'0'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>b'3'</td>\n",
       "      <td>b'1'</td>\n",
       "      <td>b'6'</td>\n",
       "      <td>b'0'</td>\n",
       "      <td>b'0'</td>\n",
       "      <td>b'0'</td>\n",
       "      <td>b'0'</td>\n",
       "      <td>b'0'</td>\n",
       "      <td>b'0'</td>\n",
       "      <td>b'1'</td>\n",
       "      <td>b'1'</td>\n",
       "      <td>b'0'</td>\n",
       "      <td>b'0'</td>\n",
       "      <td>b'1'</td>\n",
       "      <td>b'0'</td>\n",
       "      <td>b'0'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>b'5'</td>\n",
       "      <td>b'1'</td>\n",
       "      <td>b'10'</td>\n",
       "      <td>b'2'</td>\n",
       "      <td>b'1'</td>\n",
       "      <td>b'0'</td>\n",
       "      <td>b'0'</td>\n",
       "      <td>b'0'</td>\n",
       "      <td>b'0'</td>\n",
       "      <td>b'1'</td>\n",
       "      <td>b'1'</td>\n",
       "      <td>b'0'</td>\n",
       "      <td>b'0'</td>\n",
       "      <td>b'1'</td>\n",
       "      <td>b'0'</td>\n",
       "      <td>b'0'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>b'4'</td>\n",
       "      <td>b'1'</td>\n",
       "      <td>b'8'</td>\n",
       "      <td>b'2'</td>\n",
       "      <td>b'1'</td>\n",
       "      <td>b'0'</td>\n",
       "      <td>b'0'</td>\n",
       "      <td>b'0'</td>\n",
       "      <td>b'0'</td>\n",
       "      <td>b'1'</td>\n",
       "      <td>b'1'</td>\n",
       "      <td>b'0'</td>\n",
       "      <td>b'0'</td>\n",
       "      <td>b'1'</td>\n",
       "      <td>b'0'</td>\n",
       "      <td>b'0'</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  landmass  zone language religion crescent triangle  icon animate  text  \\\n",
       "0     b'4'  b'1'     b'8'     b'2'     b'0'     b'0'  b'0'    b'1'  b'1'   \n",
       "1     b'2'  b'3'     b'2'     b'0'     b'0'     b'0'  b'0'    b'0'  b'0'   \n",
       "2     b'2'  b'4'     b'2'     b'0'     b'0'     b'0'  b'0'    b'0'  b'0'   \n",
       "3     b'6'  b'2'     b'1'     b'1'     b'0'     b'0'  b'0'    b'0'  b'0'   \n",
       "4     b'5'  b'1'    b'10'     b'3'     b'0'     b'0'  b'0'    b'1'  b'0'   \n",
       "5     b'1'  b'4'     b'1'     b'1'     b'0'     b'0'  b'1'    b'0'  b'0'   \n",
       "6     b'5'  b'1'    b'10'     b'6'     b'0'     b'0'  b'0'    b'0'  b'0'   \n",
       "7     b'3'  b'1'     b'6'     b'0'     b'0'     b'0'  b'0'    b'0'  b'0'   \n",
       "8     b'5'  b'1'    b'10'     b'2'     b'1'     b'0'  b'0'    b'0'  b'0'   \n",
       "9     b'4'  b'1'     b'8'     b'2'     b'1'     b'0'  b'0'    b'0'  b'0'   \n",
       "\n",
       "    red green  blue yellow white black orange  \n",
       "0  b'1'  b'0'  b'0'   b'1'  b'1'  b'1'   b'0'  \n",
       "1  b'0'  b'0'  b'1'   b'1'  b'1'  b'0'   b'0'  \n",
       "2  b'1'  b'0'  b'1'   b'0'  b'1'  b'0'   b'0'  \n",
       "3  b'1'  b'0'  b'1'   b'1'  b'1'  b'0'   b'0'  \n",
       "4  b'1'  b'0'  b'0'   b'0'  b'1'  b'1'   b'1'  \n",
       "5  b'0'  b'0'  b'1'   b'1'  b'0'  b'1'   b'0'  \n",
       "6  b'1'  b'0'  b'1'   b'0'  b'1'  b'0'   b'0'  \n",
       "7  b'1'  b'1'  b'0'   b'0'  b'1'  b'0'   b'0'  \n",
       "8  b'1'  b'1'  b'0'   b'0'  b'1'  b'0'   b'0'  \n",
       "9  b'1'  b'1'  b'0'   b'0'  b'1'  b'0'   b'0'  "
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df_flags = train_df_flags.drop([att for att in train_df_flags if train_df_flags[att].dtype != 'object'], axis=1)\n",
    "test_df_flags = test_df_flags.drop([att for att in test_df_flags if test_df_flags[att].dtype != 'object'], axis=1)\n",
    "test_df_flags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_bayes(labels, dataframe, output_file=\"cond_prob.json\"):\n",
    "    conditional_probability = dict()\n",
    "    for label in labels:\n",
    "        prob_label = dataframe[label].value_counts() / len(dataframe)\n",
    "        if not label in conditional_probability:\n",
    "            conditional_probability[label] = dict()\n",
    "        for label_val, prob in prob_label.iteritems():\n",
    "            casted_label_val = label_val.decode('ASCII') if type(label_val) is bytes else label_val\n",
    "            conditional_probability[label][casted_label_val] = prob\n",
    "        for attribute in dataframe:\n",
    "            if attribute == label:\n",
    "                continue\n",
    "            if not attribute in conditional_probability:\n",
    "                conditional_probability[attribute] = dict()\n",
    "            conditional_probability[attribute][label] = dict()\n",
    "            cond_prob_attr_given_label_series = dataframe.groupby(attribute)[label].value_counts() /\\\n",
    "                                            dataframe.groupby(label)[attribute].count()\n",
    "            for index, value in cond_prob_attr_given_label_series.iteritems():\n",
    "                attr_value = index[0].decode('ASCII') if type(index[0]) is bytes else index[0]\n",
    "                label_value = index[1].decode('ASCII') if type(index[1]) is bytes else index[1]\n",
    "                conditional_probability[attribute][label][attr_value] = dict()\n",
    "                conditional_probability[attribute][label][attr_value][label_value] = value\n",
    "    with open(output_file, 'w') as outfile:\n",
    "        json.dump(conditional_probability, outfile)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_bayes_freq(labels, dataframe, output_file=\"freqs.json\"):\n",
    "    nc = 'numberOfClasses'\n",
    "    len_training_instances = 'N'\n",
    "    frequency = dict()\n",
    "    frequency[len_training_instances] = len(dataframe)\n",
    "    for label in labels:\n",
    "        freq_label = dataframe[label].value_counts()\n",
    "        if not label in frequency:\n",
    "            frequency[label] = dict()\n",
    "            frequency[label][nc] = len(dataframe[label].unique())\n",
    "        for label_val, freq in freq_label.iteritems():\n",
    "            casted_label_val = label_val.decode('ASCII') if type(label_val) is bytes else label_val\n",
    "            frequency[label][casted_label_val] = freq\n",
    "        for attribute in dataframe:\n",
    "            if attribute == label:\n",
    "                continue\n",
    "            if not attribute in frequency:\n",
    "                frequency[attribute] = dict()\n",
    "                frequency[attribute][nc] =len(dataframe[attribute].unique())\n",
    "                freq_attr = dataframe[attribute].nunique()\n",
    "                for att_val, freq in freq_label.iteritems():\n",
    "                    cast_att_val = att_val.decode('ASCII') if type(att_val) is bytes else att_val\n",
    "                    frequency[attribute][cast_att_val] = freq\n",
    "            frequency[attribute][label] = dict()\n",
    "            freq_attr_and_label_series = dataframe.groupby(attribute)[label].value_counts()\n",
    "            for index, value in freq_attr_and_label_series.iteritems():\n",
    "                attr_value = index[0].decode('ASCII') if type(index[0]) is bytes else index[0]\n",
    "                label_value = index[1].decode('ASCII') if type(index[1]) is bytes else index[1]\n",
    "                frequency[attribute][label][attr_value] = dict()\n",
    "                frequency[attribute][label][attr_value][label_value] = value\n",
    "    with open(output_file, 'w') as outfile:\n",
    "        json.dump(frequency, outfile)\n",
    "def apply_bayes(label, dataframe, input_file=\"freqs.json\", k=2):\n",
    "    pred_labels = []\n",
    "    key_nc = 'numberOfClasses'\n",
    "    k = 20\n",
    "    m = 2\n",
    "    y = dataframe[label].unique()\n",
    "    with open(input_file, 'r') as f:\n",
    "        freq = json.loads(f.read())\n",
    "    N = freq['N']\n",
    "    \n",
    "    \n",
    "    for _, row in dataframe.iterrows():\n",
    "        row_label = None\n",
    "        max_prob = -1000000\n",
    "        for y_hat in y:\n",
    "            cast_y_hat = y_hat.decode('ASCII') if type(y_hat) is bytes else y_hat\n",
    "            nc = freq[label].get(cast_y_hat, 0)\n",
    "            n = freq[label][key_nc]\n",
    "            p_c_laplace_estimator = (nc + k) / (N + n * k)\n",
    "            ans = p_c_laplace_estimator\n",
    "            for attr, val in row.iteritems():\n",
    "                if attr == label:\n",
    "                    continue\n",
    "                x_i = val.decode('ASCII') if type(val) is bytes else val\n",
    "                p_xi_laplace_estimator = 0\n",
    "                n_xi = freq[attr].get(x_i, 0)\n",
    "                n = freq[attr][key_nc]\n",
    "                p_xi_laplace_estimator = (n_xi + k) / (N + n * k)\n",
    "                nci = 0\n",
    "                if x_i in freq[attr][label] and cast_y_hat in freq[attr][label][x_i]:\n",
    "                    nci = freq[attr][label][x_i][cast_y_hat]\n",
    "                m_estimator_xi_given_c = (nci + m * p_xi_laplace_estimator) / (nc + m)\n",
    "                ans *= m_estimator_xi_given_c\n",
    "            if ans > max_prob:\n",
    "                row_label = cast_y_hat\n",
    "                max_prob = ans\n",
    "        pred_labels.append(row_label)\n",
    "    df_label = dataframe[label]\n",
    "    df_pred_labels = pd.DataFrame({'pred_' + label : pred_labels })\n",
    "    return pd.concat([df_label, df_pred_labels], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = ['red','green','blue','yellow','white','black','orange']\n",
    "train_bayes_freq(labels, train_df_flags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    red pred_red\n",
      "0  b'1'        0\n",
      "1  b'0'        0\n",
      "2  b'1'        0\n",
      "3  b'1'        0\n",
      "4  b'1'        0\n",
      "5  b'0'        0\n",
      "6  b'1'        0\n",
      "7  b'1'        0\n",
      "8  b'1'        0\n",
      "9  b'1'        0\n",
      "  green pred_green\n",
      "0  b'0'          1\n",
      "1  b'0'          0\n",
      "2  b'0'          1\n",
      "3  b'0'          0\n",
      "4  b'0'          1\n",
      "5  b'0'          1\n",
      "6  b'0'          0\n",
      "7  b'1'          1\n",
      "8  b'1'          1\n",
      "9  b'1'          1\n",
      "   blue pred_blue\n",
      "0  b'0'         0\n",
      "1  b'1'         0\n",
      "2  b'1'         0\n",
      "3  b'1'         0\n",
      "4  b'0'         1\n",
      "5  b'1'         0\n",
      "6  b'1'         0\n",
      "7  b'0'         0\n",
      "8  b'0'         0\n",
      "9  b'0'         0\n",
      "  yellow pred_yellow\n",
      "0   b'1'           1\n",
      "1   b'1'           1\n",
      "2   b'0'           1\n",
      "3   b'1'           1\n",
      "4   b'0'           1\n",
      "5   b'1'           1\n",
      "6   b'0'           1\n",
      "7   b'0'           1\n",
      "8   b'0'           1\n",
      "9   b'0'           1\n",
      "  white pred_white\n",
      "0  b'1'          0\n",
      "1  b'1'          0\n",
      "2  b'1'          0\n",
      "3  b'1'          0\n",
      "4  b'1'          0\n",
      "5  b'0'          0\n",
      "6  b'1'          0\n",
      "7  b'1'          0\n",
      "8  b'1'          0\n",
      "9  b'1'          0\n",
      "  black pred_black\n",
      "0  b'1'          0\n",
      "1  b'0'          0\n",
      "2  b'0'          0\n",
      "3  b'0'          0\n",
      "4  b'1'          0\n",
      "5  b'1'          0\n",
      "6  b'0'          0\n",
      "7  b'0'          0\n",
      "8  b'0'          0\n",
      "9  b'0'          0\n",
      "  orange pred_orange\n",
      "0   b'0'           1\n",
      "1   b'0'           1\n",
      "2   b'0'           1\n",
      "3   b'0'           1\n",
      "4   b'1'           1\n",
      "5   b'0'           1\n",
      "6   b'0'           1\n",
      "7   b'0'           1\n",
      "8   b'0'           1\n",
      "9   b'0'           1\n"
     ]
    }
   ],
   "source": [
    "for lab in labels:\n",
    "    print(apply_bayes(lab, test_df_flags))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_df_flags['blue'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('0', 0.8213391783670262)\n",
      "('0', 0.8474030471879673)\n",
      "('0', 0.8474124555700832)\n",
      "('0', 0.8474030471879673)\n",
      "('0', 0.19171895912709266)\n",
      "('0', 0.8206794786237728)\n",
      "('0', 0.8474124555700832)\n",
      "('0', 0.8474116915423449)\n",
      "('0', 0.8474116915423409)\n",
      "('0', 0.8474116915423409)\n"
     ]
    }
   ],
   "source": [
    "for i in [('0', 0.8213391783670262), ('0', 0.8474030471879673), ('0', 0.8474124555700832), ('0', 0.8474030471879673), ('0', 0.19171895912709266), ('0', 0.8206794786237728), ('0', 0.8474124555700832), ('0', 0.8474116915423449), ('0', 0.8474116915423409), ('0', 0.8474116915423409)]:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
