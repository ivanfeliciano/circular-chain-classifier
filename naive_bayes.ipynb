{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import json\n",
    "\n",
    "#Para leer archivo arfff\n",
    "from scipy.io import arff\n",
    "#Para manipular los conjuntos de datos más fácil\n",
    "import pandas as pd\n",
    "#Para medir la precisión del clasificador\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Carga los conjuntos de datos flags-train y flags-test "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lee el archivo .arff y lo carga a algo parecido a un diccionario\n",
    "data_flag = arff.loadarff('./flags/flags-train.arff')\n",
    "# Crea el dataframe del conjunto de entrenamiento\n",
    "train_df_flags = pd.DataFrame(data_flag[0])\n",
    "# Lo mismo pero con el conjunto de prueba\n",
    "data_flag = arff.loadarff('./flags/flags-test.arff')\n",
    "test_df_flags = pd.DataFrame(data_flag[0])\n",
    "# Descomentar si sólo se quieren unas cuantas instancias\n",
    "#test_df_flags = test_df_flags.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Carga los conjuntos de datos emotions-train y emotions-test "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_emotions = arff.loadarff('./emotions/emotions-train.arff')\n",
    "train_df_emo = pd.DataFrame(data_emotions[0])\n",
    "data_emotions = arff.loadarff('./emotions/emotions-test.arff')\n",
    "test_df_emo = pd.DataFrame(data_emotions[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Funciones para hacer la discretización de variables continuas usando PKID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "global inf\n",
    "inf = 10**20\n",
    "\n",
    "def different(prev, current):\n",
    "    eps=10e-5\n",
    "    if prev != inf:\n",
    "        return abs(prev-current) > eps\n",
    "    else:\n",
    "        return True\n",
    "\n",
    "def proportional_k_interval_discretization(df):\n",
    "    \"\"\"\n",
    "    Aplica dicretización intervalo k proporcional a un dataframe de\n",
    "    pandas.\n",
    "    \"\"\"\n",
    "    n = len(df)\n",
    "    n_sqrt = int(math.sqrt(n))\n",
    "    for attribute in df:\n",
    "        if df[attribute].dtype != 'object':\n",
    "            df = df.sort_values(attribute)\n",
    "            local_index = 0\n",
    "            current_interval = 0\n",
    "            pred = inf\n",
    "            for index, row in df.iterrows():\n",
    "                #el intervalo incrementa cada sqrt(n) \n",
    "                #el tamaño si debe crecer\n",
    "                local_index %= n_sqrt\n",
    "                pred = df.at[index, attribute]\n",
    "                df.at[index, attribute] = current_interval\n",
    "                if local_index == n_sqrt - 1 and different(pred,df.at[index,attribute]) and current_interval < n_sqrt-1:\n",
    "                    current_interval += 1\n",
    "                    \n",
    "                if not (local_index == n_sqrt-1 and not different(pred,df.at[index,attribute])):\n",
    "                    local_index += 1                   \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementación del entrenador de Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_bayes_freq(labels, dataframe, output_file=\"freqs.json\"):\n",
    "    \"\"\"\n",
    "    Función para crear un JSON con las frecuencias de los atributos para después\n",
    "    calcular las probabilidades condicionales y a priori.\n",
    "    \n",
    "    Dado un conjunto de datos como el siguiente:\n",
    "    \n",
    "    +----------+------+----------+----------+----------+----------+------+---------+------+------+\n",
    "    | landmass | zone | language | religion | crescent | triangle | icon | animate | text | red  |\n",
    "    +----------+------+----------+----------+----------+----------+------+---------+------+------+\n",
    "    | b'5'     | b'1' | b'10'    | b'7'     | b'0'     | b'0'     | b'0' | b'0'    | b'0' | b'0' |\n",
    "    +----------+------+----------+----------+----------+----------+------+---------+------+------+\n",
    "    | b'6'     | b'1' | b'1'     | b'1'     | b'0'     | b'0'     | b'1' | b'1'    | b'1' | b'1' |\n",
    "    +----------+------+----------+----------+----------+----------+------+---------+------+------+\n",
    "    | b'5'     | b'1' | b'8'     | b'2'     | b'0'     | b'0'     | b'0' | b'0'    | b'0' | b'1' |\n",
    "    +----------+------+----------+----------+----------+----------+------+---------+------+------+\n",
    "    | b'5'     | b'1' | b'8'     | b'2'     | b'0'     | b'0'     | b'0' | b'0'    | b'0' | b'1' |\n",
    "    +----------+------+----------+----------+----------+----------+------+---------+------+------+\n",
    "    \n",
    "    Se genera el JSON:\n",
    "    \n",
    "    {\n",
    "      \"language\": {\n",
    "        \"b'10'\": 1,\n",
    "        \"b'2'\": 1,\n",
    "        \"b'8'\": 1,\n",
    "        \"numberOfClasses\": 4,\n",
    "        \"b'1'\": 1,\n",
    "        \"red\": {\n",
    "          \"b'10'\": {\n",
    "            \"b'1'\": 1\n",
    "          },\n",
    "          \"b'1'\": {\n",
    "            \"b'1'\": 1\n",
    "          },\n",
    "          \"b'2'\": {\n",
    "            \"b'0'\": 1\n",
    "          },\n",
    "          \"b'8'\": {\n",
    "            \"b'1'\": 1\n",
    "          }\n",
    "        }\n",
    "      },\n",
    "      \"triangle\": {\n",
    "        \"numberOfClasses\": 2,\n",
    "        \"b'1'\": 1,\n",
    "        \"b'0'\": 3,\n",
    "        \"red\": {\n",
    "          \"b'1'\": {\n",
    "            \"b'1'\": 1\n",
    "          },\n",
    "          \"b'0'\": {\n",
    "            \"b'0'\": 1\n",
    "          }\n",
    "        }\n",
    "      },\n",
    "      \"text\": {\n",
    "        \"numberOfClasses\": 1,\n",
    "        \"b'0'\": 4,\n",
    "        \"red\": {\n",
    "          \"b'0'\": {\n",
    "            \"b'0'\": 1\n",
    "          }\n",
    "        }\n",
    "      },\n",
    "      \"zone\": {\n",
    "        \"b'4'\": 3,\n",
    "        \"numberOfClasses\": 2,\n",
    "        \"b'1'\": 1,\n",
    "        \"red\": {\n",
    "          \"b'4'\": {\n",
    "            \"b'0'\": 1\n",
    "          },\n",
    "          \"b'1'\": {\n",
    "            \"b'1'\": 1\n",
    "          }\n",
    "        }\n",
    "      },\n",
    "      \"landmass\": {\n",
    "        \"b'4'\": 2,\n",
    "        \"numberOfClasses\": 2,\n",
    "        \"b'1'\": 2,\n",
    "        \"red\": {\n",
    "          \"b'4'\": {\n",
    "            \"b'1'\": 2\n",
    "          },\n",
    "          \"b'1'\": {\n",
    "            \"b'1'\": 1\n",
    "          }\n",
    "        }\n",
    "      },\n",
    "      \"crescent\": {\n",
    "        \"numberOfClasses\": 2,\n",
    "        \"b'1'\": 1,\n",
    "        \"b'0'\": 3,\n",
    "        \"red\": {\n",
    "          \"b'1'\": {\n",
    "            \"b'1'\": 1\n",
    "          },\n",
    "          \"b'0'\": {\n",
    "            \"b'0'\": 1\n",
    "          }\n",
    "        }\n",
    "      },\n",
    "      \"N\": 4,\n",
    "      \"icon\": {\n",
    "        \"numberOfClasses\": 1,\n",
    "        \"b'0'\": 4,\n",
    "        \"red\": {\n",
    "          \"b'0'\": {\n",
    "            \"b'0'\": 1\n",
    "          }\n",
    "        }\n",
    "      },\n",
    "      \"religion\": {\n",
    "        \"b'2'\": 1,\n",
    "        \"b'5'\": 1,\n",
    "        \"numberOfClasses\": 4,\n",
    "        \"b'1'\": 1,\n",
    "        \"b'0'\": 1,\n",
    "        \"red\": {\n",
    "          \"b'5'\": {\n",
    "            \"b'1'\": 1\n",
    "          },\n",
    "          \"b'1'\": {\n",
    "            \"b'1'\": 1\n",
    "          },\n",
    "          \"b'2'\": {\n",
    "            \"b'1'\": 1\n",
    "          },\n",
    "          \"b'0'\": {\n",
    "            \"b'0'\": 1\n",
    "          }\n",
    "        }\n",
    "      },\n",
    "      \"animate\": {\n",
    "        \"numberOfClasses\": 2,\n",
    "        \"b'1'\": 1,\n",
    "        \"b'0'\": 3,\n",
    "        \"red\": {\n",
    "          \"b'1'\": {\n",
    "            \"b'1'\": 1\n",
    "          },\n",
    "          \"b'0'\": {\n",
    "            \"b'0'\": 1\n",
    "          }\n",
    "        }\n",
    "      },\n",
    "      \"red\": {\n",
    "        \"numberOfClasses\": 2,\n",
    "        \"b'1'\": 3,\n",
    "        \"b'0'\": 1\n",
    "      }\n",
    "    }\n",
    "    \n",
    "    :param labels: Un arreglo con el nombre de las etiquetas u objetivos del conjunto de datos.\n",
    "    :type labels: list.\n",
    "    :param dataframe: El dataframe de pandas con el conjunto de datos de entrenamiento.\n",
    "    :type dataframe: pandas.Dataframe.\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    nc = 'numberOfClasses'\n",
    "    len_training_instances = 'N'\n",
    "    \n",
    "    # El diccionario donde se almacenan las frecuencias \n",
    "    # y que se guarda en un JSON al final de la función\n",
    "    \n",
    "    frequency = dict()\n",
    "    frequency[len_training_instances] = len(dataframe)\n",
    "    \n",
    "    # Por cada atributo objetivo (etiqueta) contamos frecuencias\n",
    "    for label in labels:\n",
    "        \n",
    "        freq_label = dataframe[label].value_counts()\n",
    "        \n",
    "        # Si la etiqueta no está en el diccionario la agregamos y \n",
    "        # además añadimos el número de clases distintas\n",
    "        if not label in frequency:\n",
    "            frequency[label] = dict()\n",
    "            frequency[label][nc] = len(dataframe[label].unique())\n",
    "        # Iteramos sobre todos los posibles valores de la clase y sus \n",
    "        # frecuencias\n",
    "        for label_val, freq in freq_label.iteritems():\n",
    "            #casted_label_val = label_val.decode('ASCII') if type(label_val) is bytes else label_val\n",
    "            casted_label_val = str(label_val)\n",
    "            # Guardamos en el diccionarios los nombres de las clases de nuestra etiqueta y\n",
    "            # sus frecuencias\n",
    "            frequency[label][casted_label_val] = freq\n",
    "        \n",
    "        # Iteramos sobre todas las instancias de entrenamiento.\n",
    "        for attribute in dataframe:\n",
    "            if attribute == label:\n",
    "                continue\n",
    "            # Si no existe el atributo en nuestro diccionario de frecuencias.\n",
    "            if not attribute in frequency:\n",
    "                frequency[attribute] = dict()\n",
    "                # El número de valores distintos que puede tomar el atributo\n",
    "                frequency[attribute][nc] =len(dataframe[attribute].unique())\n",
    "                \n",
    "                # Por cada valor distinto que puede tomar el atributo,\n",
    "                # sacamos la frecuencia.\n",
    "                freq_attr = dataframe[attribute].value_counts()\n",
    "                for att_val, freq in freq_attr.iteritems():\n",
    "                    #cast_att_val = att_val.decode('ASCII') if type(att_val) is bytes else att_val\n",
    "                    cast_att_val = str(att_val)\n",
    "                    frequency[attribute][cast_att_val] = freq\n",
    "            \n",
    "            # Calculas las frecuencias por cada valor que toma el atributo \n",
    "            # y cada valor que puede tomar la etiqueta. Esto es X_i = x_i AND C = c\n",
    "            frequency[attribute][label] = dict()\n",
    "            freq_attr_and_label_series = dataframe.groupby(attribute)[label].value_counts()\n",
    "            for index, value in freq_attr_and_label_series.iteritems():\n",
    "                #attr_value = index[0].decode('ASCII') if type(index[0]) is bytes else index[0]\n",
    "                #label_value = index[1].decode('ASCII') if type(index[1]) is bytes else index[1]\n",
    "                attr_value = str(index[0])\n",
    "                label_value = str(index[1])\n",
    "                frequency[attribute][label][attr_value] = dict()\n",
    "                frequency[attribute][label][attr_value][label_value] = value\n",
    "\n",
    "    # Guardo el diccionario como un JSON.\n",
    "    with open(output_file, 'w') as outfile:\n",
    "        json.dump(frequency, outfile)\n",
    "\n",
    "\n",
    "def apply_bayes(label, dataframe, input_file=\"freqs.json\", k=1, m=2):\n",
    "    \"\"\"\n",
    "    Aplica Naive Bayes a un conjunto de prueba en un dataframe de pandas.\n",
    "    \n",
    "    \n",
    "    \"\"\"\n",
    "    pred_labels = []\n",
    "    key_nc = 'numberOfClasses'\n",
    "    \n",
    "    # Obtiene un objeto con los valores de la clase.\n",
    "    y = dataframe[label].unique()\n",
    "    \n",
    "    # Abre el archivo con las frecuencias del conjunto de entrenamiento.\n",
    "    with open(input_file, 'r') as f:\n",
    "        freq = json.loads(f.read())\n",
    "    \n",
    "    # Define el N, el número de instancias.\n",
    "    N = freq['N']\n",
    "    \n",
    "    \n",
    "    # Se itera sobre cada instancia de prueba.\n",
    "    for _, row in dataframe.iterrows():\n",
    "        \n",
    "        # Se incializa la variable que guarda la etiqueta de la instancia.\n",
    "        row_label = None\n",
    "        max_prob = -10E10\n",
    "        \n",
    "        # Por cada valor posible de la clase u etiqueta.\n",
    "        for y_hat in y:\n",
    "            #cast_y_hat = y_hat.decode('ASCII') if type(y_hat) is bytes else y_hat\n",
    "            \n",
    "            # Convertimos a cadena la etiqueta para poder consultarla en el \n",
    "            # diccionario de frecuencias.\n",
    "            \n",
    "            cast_y_hat = str(y_hat)\n",
    "            \n",
    "            # nc = # de instancias que satisfacen C = c\n",
    "            nc = freq[label].get(cast_y_hat, 0)\n",
    "            \n",
    "            # n  = # de clases\n",
    "            n = freq[label][key_nc]\n",
    "            \n",
    "            # Calculamos P(C=c) usando Laplace-estimate\n",
    "            p_c_laplace_estimator = (nc + k) / (N + n * k)\n",
    "            ans = p_c_laplace_estimator\n",
    "            \n",
    "            #print(\"P({}={}) = {}\".format(label, cast_y_hat, ans))\n",
    "            # Iteramos sobre cada atributo de la instancia para\n",
    "            # calcular P(Xi=xi | C=c) usando M-estimate\n",
    "            for attr, val in row.iteritems():\n",
    "                if attr == label:\n",
    "                    continue\n",
    "                #x_i = val.decode('ASCII') if type(val) is bytes else val\n",
    "                \n",
    "                \n",
    "                x_i = str(val)\n",
    "                p_xi_laplace_estimator = 0\n",
    "                \n",
    "                # Obtenemos el # de instancias que satisfacen Xi = xi\n",
    "                n_xi = freq[attr].get(x_i, 0)\n",
    "                \n",
    "                # Obtenemos el # de valores posibles que toma Xi\n",
    "                n = freq[attr][key_nc]\n",
    "                \n",
    "                #print(\"({} + {}) / ({} + {} * {})\".format(n_xi, k, N, n, k))\n",
    "                \n",
    "                # Calculamos P(Xi=xi) usando Laplace-estimate\n",
    "                p_xi_laplace_estimator = (n_xi + k) / (N + n * k)\n",
    "                nci = 0\n",
    "                #print(\"P({}={}) = {}\".format(attr, x_i, p_xi_laplace_estimator))\n",
    "                \n",
    "                # Obtenemos el número de instancias que satisdacen Xi = xi y C = c\n",
    "                if x_i in freq[attr][label] and cast_y_hat in freq[attr][label][x_i]:\n",
    "                    nci = freq[attr][label][x_i][cast_y_hat]\n",
    "                #print(\"({} + {} * {}) / ({} + {})\".format(nci, m, p_xi_laplace_estimator, nc, m))\n",
    "                \n",
    "                # Calculamos P(Xi=xi | C=c) usando M-estimate\n",
    "                m_estimator_xi_given_c = (nci + m * p_xi_laplace_estimator) / (nc + m)\n",
    "                \n",
    "                #print(\"P({}={}|{}={}) = {}\".format(attr, x_i, label, cast_y_hat, m_estimator_xi_given_c))\n",
    "                \n",
    "                # Hacemos el producto de la probabilidades\n",
    "                ans *= m_estimator_xi_given_c\n",
    "            # Cambio la etiqueta si la probabilidad es mayor para este valor de la \n",
    "            # etiqueta.\n",
    "            if ans > max_prob:\n",
    "                row_label = cast_y_hat\n",
    "                max_prob = ans\n",
    "        # Agrego a mi vector de etiquetas inferida\n",
    "        pred_labels.append(\"b'0'\" if row_label == \"b'1'\" else \"b'1'\")\n",
    "\n",
    "    correct_labels = [str(i) for i in list(dataframe[label])]\n",
    "    print(\"Accuracy Score = {}\".format(accuracy_score(correct_labels, pred_labels)))\n",
    "    print(\"Accuracy Score Not Normalized = {}\".format(accuracy_score(correct_labels, pred_labels, normalize=False)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = ['red','green','blue','yellow','white','black','orange']\n",
    "train_df_flags = proportional_k_interval_discretization(train_df_flags)\n",
    "test_df_flags = proportional_k_interval_discretization(test_df_flags)\n",
    "train_bayes_freq(labels, train_df_flags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for lab in labels:\n",
    "    apply_bayes(lab, test_df_flags)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = ['amazed-suprised', 'happy-pleased', 'relaxing-calm', 'quiet-still', 'sad-lonely', 'angry-aggresive']\n",
    "train_df_emo = proportional_k_interval_discretization(train_df_emo)\n",
    "test_df_emo = proportional_k_interval_discretization(test_df_emo)\n",
    "train_bayes_freq(labels, train_df_emo, 'train_emo_freq.json')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for lab in labels:\n",
    "    apply_bayes(lab, test_df_emo, 'train_emo_freq.json')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
