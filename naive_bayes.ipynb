{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import json\n",
    "import numpy as np\n",
    "#Para leer archivo arfff\n",
    "from scipy.io import arff\n",
    "#Para manipular los conjuntos de datos más fácil\n",
    "import pandas as pd\n",
    "#Para medir la precisión del clasificador\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Carga los conjuntos de datos flags-train y flags-test "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(129, 26)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Lee el archivo .arff y lo carga a algo parecido a un diccionario\n",
    "data_flag = arff.loadarff('./flags/flags-train.arff')\n",
    "# Crea el dataframe del conjunto de entrenamiento\n",
    "train_df_flags = pd.DataFrame(data_flag[0])\n",
    "# Lo mismo pero con el conjunto de prueba\n",
    "data_flag = arff.loadarff('./flags/flags-test.arff')\n",
    "test_df_flags = pd.DataFrame(data_flag[0])\n",
    "# Descomentar si sólo se quieren unas cuantas instancias\n",
    "labels = ['red','green','blue','yellow','white','black','orange']\n",
    "train_df_flags.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.base import clone\n",
    "from sklearn.utils.validation import check_is_fitted\n",
    "class CircularChainClassifier(object):\n",
    "\t\"\"\"\n",
    "\tSúper clase de clasificador en cadena circular, recibe\n",
    "\tcomo parámetros un dataframe de pandas que contiene al \n",
    "\tconjunto de datos y la lista de atributos que son las posibles\n",
    "\tetiquetas de cada ejemplo.\n",
    "\t\"\"\"\n",
    "\tdef __init__(self, classifier):\n",
    "\t\tself.classifier = classifier\n",
    "\n",
    "\tdef train(self, X, labels):\n",
    "\t\tself.list_of_classifiers = { label : clone(self.classifier) for label in labels }\n",
    "\t\tfor lab in self.list_of_classifiers:\n",
    "\t\t\tprint(id(self.list_of_classifiers[lab]))\n",
    "\t\tself.train_set_x = X\n",
    "\t\tself.labels = labels\n",
    "\t\tself.visited = { label : False for label in labels }\n",
    "\t\tfor label in self.labels:\n",
    "\t\t\tself.train_one_link(label)\n",
    "\tdef train_one_link(self, label, weirdo=False):\n",
    "\t\tX = self.drop_not_depend_on_columns(self.train_set_x, label)\n",
    "\t\ty = self.train_set_x[label]\n",
    "\t\tprint(\"label {} with shape {}\".format(label, X.shape))\n",
    "\t\tself.list_of_classifiers[label].fit(X, y)\n",
    "\t\tprint(self.list_of_classifiers[label].fit(X, y))\n",
    "\tdef drop_not_depend_on_columns(self, X, label):\n",
    "\t\tlabel_index = self.labels.index(label)\n",
    "\t\tif label_index + 1 == len(self.labels):\n",
    "\t\t\treturn X.drop(label, axis=1)\n",
    "\t\tlabels_to_drop = self.labels[label_index:]\n",
    "\t\tX = X.drop(labels_to_drop, axis=1)\n",
    "\t\treturn X\n",
    "\tdef run(self, X):\n",
    "\t\tprint(\"running...\")\n",
    "\t\tfor classifier_label in self.list_of_classifiers:\n",
    "\t\t\tprint(classifier_label)\n",
    "\t\t\tlabel = classifier_label\n",
    "\t\t\ty = X[label]\n",
    "\t\t\tX_hat = self.drop_not_depend_on_columns(X, classifier_label)\n",
    "\t\t\tprint(X_hat.shape)\n",
    "\t\t\ttry:\n",
    "\t\t\t\ty_pred = self.list_of_classifiers[classifier_label].predict(X_hat)\n",
    "\t\t\t\tprint(y_pred)\n",
    "\t\t\texcept Exception as e:\n",
    "\t\t\t\tprint(e)\n",
    "\t\t\tprint(\"Accuracy score for classifier {} = {}\".format(label, accuracy_score(y, y_pred)))\n",
    "\tdef classify(self):\n",
    "\t\tpass\n",
    "\tdef evaluation(self):\n",
    "\t\tpass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "139946612634904\n",
      "139946612635072\n",
      "139946612634568\n",
      "139946612633672\n",
      "139946612634848\n",
      "139946612634232\n",
      "139946612633896\n",
      "label red with shape (129, 19)\n",
      "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)\n",
      "label green with shape (129, 20)\n",
      "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)\n",
      "label blue with shape (129, 21)\n",
      "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)\n",
      "label yellow with shape (129, 22)\n",
      "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)\n",
      "label white with shape (129, 23)\n",
      "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)\n",
      "label black with shape (129, 24)\n",
      "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)\n",
      "label orange with shape (129, 25)\n",
      "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)\n",
      "running...\n",
      "yellow\n",
      "(65, 22)\n",
      "[0 0 1 1 1 1 0 0 1 0 0 0 1 0 1 0 1 0 1 1 1 0 0 1 1 1 1 1 0 1 1 1 1 1 0 0 1\n",
      " 0 1 0 0 0 1 0 0 1 1 1 0 0 0 1 1 1 1 1 0 1 0 0 0 1 0 0 1]\n",
      "Accuracy score for classifier yellow = 0.676923076923077\n",
      "blue\n",
      "(65, 21)\n",
      "[0 1 1 1 1 1 1 0 0 0 0 0 0 1 1 0 1 0 1 1 1 0 0 1 1 1 0 1 0 1 0 1 1 1 0 1 1\n",
      " 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 1 1 1 1 0 0 1 0 0 1 0 1 1]\n",
      "Accuracy score for classifier blue = 0.6153846153846154\n",
      "black\n",
      "(65, 24)\n",
      "[0 0 0 0 1 1 0 0 1 0 0 0 1 0 1 0 1 0 1 0 1 0 0 1 1 1 1 1 0 0 1 1 1 0 0 0 0\n",
      " 1 1 1 0 0 0 1 1 1 1 0 0 0 0 0 1 1 1 1 0 1 0 0 0 0 0 0 1]\n",
      "Accuracy score for classifier black = 0.6307692307692307\n",
      "orange\n",
      "(65, 25)\n",
      "[0 0 0 1 1 1 0 0 1 0 0 0 1 0 0 0 1 0 1 1 1 0 0 1 1 1 1 1 0 0 1 0 1 0 0 0 1\n",
      " 0 1 0 0 0 1 1 0 1 0 0 0 0 0 0 0 1 1 0 0 1 0 0 0 0 0 0 1]\n",
      "Accuracy score for classifier orange = 0.6153846153846154\n",
      "red\n",
      "(65, 19)\n",
      "[1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 0 1]\n",
      "Accuracy score for classifier red = 0.7076923076923077\n",
      "white\n",
      "(65, 23)\n",
      "[1 1 1 1 1 1 1 0 1 0 0 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 0 1 1 1 1 1\n",
      " 1 1 1 1 0 1 1 1 1 1 0 0 1 1 0 1 1 1 1 1 1 1 1 0 1 1 1 1]\n",
      "Accuracy score for classifier white = 0.7076923076923077\n",
      "green\n",
      "(65, 20)\n",
      "[0 0 1 1 1 1 0 0 1 0 0 0 1 0 0 1 1 0 1 1 1 1 0 1 1 1 1 1 0 0 1 1 1 0 0 1 1\n",
      " 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 0 1 1 0 1 0 1 1 1 0 0 1]\n",
      "Accuracy score for classifier green = 0.5076923076923077\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "le = LabelEncoder()\n",
    "labels = ['red','green','blue','yellow','white','black','orange']\n",
    "train_df_flags = train_df_flags[train_df_flags.columns[:]].apply(le.fit_transform)\n",
    "test_df_flags = test_df_flags[test_df_flags.columns[:]].apply(le.fit_transform)\n",
    "ccc = CircularChainClassifier(MultinomialNB())\n",
    "ccc.train(train_df_flags, labels)\n",
    "ccc.run(test_df_flags)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Carga los conjuntos de datos emotions-train y emotions-test "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_emotions = arff.loadarff('./emotions/emotions-train.arff')\n",
    "train_df_emo = pd.DataFrame(data_emotions[0])\n",
    "data_emotions = arff.loadarff('./emotions/emotions-test.arff')\n",
    "test_df_emo = pd.DataFrame(data_emotions[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Funciones para hacer la discretización de variables continuas usando PKID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "global inf\n",
    "inf = 10**20\n",
    "\n",
    "def different(prev, current):\n",
    "    eps=10e-5\n",
    "    if prev != inf:\n",
    "        return abs(prev-current) > eps\n",
    "    else:\n",
    "        return True\n",
    "\n",
    "def proportional_k_interval_discretization(df):\n",
    "    \"\"\"\n",
    "    Aplica dicretización intervalo k proporcional a un dataframe de\n",
    "    pandas.\n",
    "    \"\"\"\n",
    "    n = len(df)\n",
    "    n_sqrt = int(math.sqrt(n))\n",
    "    for attribute in df:\n",
    "        if df[attribute].dtype != 'object':\n",
    "            df = df.sort_values(attribute)\n",
    "            local_index = 0\n",
    "            current_interval = 0\n",
    "            pred = inf\n",
    "            for index, row in df.iterrows():\n",
    "                #el intervalo incrementa cada sqrt(n) \n",
    "                #el tamaño si debe crecer\n",
    "                local_index %= n_sqrt\n",
    "                pred = df.at[index, attribute]\n",
    "                df.at[index, attribute] = current_interval\n",
    "                if local_index == n_sqrt - 1 and different(pred, df.at[index,attribute]) and current_interval < n_sqrt-1:\n",
    "                    current_interval += 1\n",
    "                    \n",
    "                if not (local_index == n_sqrt-1 and not different(pred,df.at[index,attribute])):\n",
    "                    local_index += 1                   \n",
    "    return df.sort_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementación del entrenador de Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_bayes_freq(labels, dataframe, output_file=\"freqs.json\"):\n",
    "    \"\"\"\n",
    "    Función para crear un JSON con las frecuencias de los atributos para después\n",
    "    calcular las probabilidades condicionales y a priori.\n",
    "    \n",
    "    Dado un conjunto de datos como el siguiente:\n",
    "    \n",
    "    +----------+------+----------+----------+----------+----------+------+---------+------+------+\n",
    "    | landmass | zone | language | religion | crescent | triangle | icon | animate | text | red  |\n",
    "    +----------+------+----------+----------+----------+----------+------+---------+------+------+\n",
    "    | b'5'     | b'1' | b'10'    | b'7'     | b'0'     | b'0'     | b'0' | b'0'    | b'0' | b'0' |\n",
    "    +----------+------+----------+----------+----------+----------+------+---------+------+------+\n",
    "    | b'6'     | b'1' | b'1'     | b'1'     | b'0'     | b'0'     | b'1' | b'1'    | b'1' | b'1' |\n",
    "    +----------+------+----------+----------+----------+----------+------+---------+------+------+\n",
    "    | b'5'     | b'1' | b'8'     | b'2'     | b'0'     | b'0'     | b'0' | b'0'    | b'0' | b'1' |\n",
    "    +----------+------+----------+----------+----------+----------+------+---------+------+------+\n",
    "    | b'5'     | b'1' | b'8'     | b'2'     | b'0'     | b'0'     | b'0' | b'0'    | b'0' | b'1' |\n",
    "    +----------+------+----------+----------+----------+----------+------+---------+------+------+\n",
    "    \n",
    "    Se genera el JSON:\n",
    "    \n",
    "    {\n",
    "      \"language\": {\n",
    "        \"b'10'\": 1,\n",
    "        \"b'2'\": 1,\n",
    "        \"b'8'\": 1,\n",
    "        \"numberOfClasses\": 4,\n",
    "        \"b'1'\": 1,\n",
    "        \"red\": {\n",
    "          \"b'10'\": {\n",
    "            \"b'1'\": 1\n",
    "          },\n",
    "          \"b'1'\": {\n",
    "            \"b'1'\": 1\n",
    "          },\n",
    "          \"b'2'\": {\n",
    "            \"b'0'\": 1\n",
    "          },\n",
    "          \"b'8'\": {\n",
    "            \"b'1'\": 1\n",
    "          }\n",
    "        }\n",
    "      },\n",
    "      \"triangle\": {\n",
    "        \"numberOfClasses\": 2,\n",
    "        \"b'1'\": 1,\n",
    "        \"b'0'\": 3,\n",
    "        \"red\": {\n",
    "          \"b'1'\": {\n",
    "            \"b'1'\": 1\n",
    "          },\n",
    "          \"b'0'\": {\n",
    "            \"b'0'\": 1\n",
    "          }\n",
    "        }\n",
    "      },\n",
    "      \"text\": {\n",
    "        \"numberOfClasses\": 1,\n",
    "        \"b'0'\": 4,\n",
    "        \"red\": {\n",
    "          \"b'0'\": {\n",
    "            \"b'0'\": 1\n",
    "          }\n",
    "        }\n",
    "      },\n",
    "      \"zone\": {\n",
    "        \"b'4'\": 3,\n",
    "        \"numberOfClasses\": 2,\n",
    "        \"b'1'\": 1,\n",
    "        \"red\": {\n",
    "          \"b'4'\": {\n",
    "            \"b'0'\": 1\n",
    "          },\n",
    "          \"b'1'\": {\n",
    "            \"b'1'\": 1\n",
    "          }\n",
    "        }\n",
    "      },\n",
    "      \"landmass\": {\n",
    "        \"b'4'\": 2,\n",
    "        \"numberOfClasses\": 2,\n",
    "        \"b'1'\": 2,\n",
    "        \"red\": {\n",
    "          \"b'4'\": {\n",
    "            \"b'1'\": 2\n",
    "          },\n",
    "          \"b'1'\": {\n",
    "            \"b'1'\": 1\n",
    "          }\n",
    "        }\n",
    "      },\n",
    "      \"crescent\": {\n",
    "        \"numberOfClasses\": 2,\n",
    "        \"b'1'\": 1,\n",
    "        \"b'0'\": 3,\n",
    "        \"red\": {\n",
    "          \"b'1'\": {\n",
    "            \"b'1'\": 1\n",
    "          },\n",
    "          \"b'0'\": {\n",
    "            \"b'0'\": 1\n",
    "          }\n",
    "        }\n",
    "      },\n",
    "      \"N\": 4,\n",
    "      \"icon\": {\n",
    "        \"numberOfClasses\": 1,\n",
    "        \"b'0'\": 4,\n",
    "        \"red\": {\n",
    "          \"b'0'\": {\n",
    "            \"b'0'\": 1\n",
    "          }\n",
    "        }\n",
    "      },\n",
    "      \"religion\": {\n",
    "        \"b'2'\": 1,\n",
    "        \"b'5'\": 1,\n",
    "        \"numberOfClasses\": 4,\n",
    "        \"b'1'\": 1,\n",
    "        \"b'0'\": 1,\n",
    "        \"red\": {\n",
    "          \"b'5'\": {\n",
    "            \"b'1'\": 1\n",
    "          },\n",
    "          \"b'1'\": {\n",
    "            \"b'1'\": 1\n",
    "          },\n",
    "          \"b'2'\": {\n",
    "            \"b'1'\": 1\n",
    "          },\n",
    "          \"b'0'\": {\n",
    "            \"b'0'\": 1\n",
    "          }\n",
    "        }\n",
    "      },\n",
    "      \"animate\": {\n",
    "        \"numberOfClasses\": 2,\n",
    "        \"b'1'\": 1,\n",
    "        \"b'0'\": 3,\n",
    "        \"red\": {\n",
    "          \"b'1'\": {\n",
    "            \"b'1'\": 1\n",
    "          },\n",
    "          \"b'0'\": {\n",
    "            \"b'0'\": 1\n",
    "          }\n",
    "        }\n",
    "      },\n",
    "      \"red\": {\n",
    "        \"numberOfClasses\": 2,\n",
    "        \"b'1'\": 3,\n",
    "        \"b'0'\": 1\n",
    "      }\n",
    "    }\n",
    "    \n",
    "    :param labels: Un arreglo con el nombre de las etiquetas u objetivos del conjunto de datos.\n",
    "    :type labels: list.\n",
    "    :param dataframe: El dataframe de pandas con el conjunto de datos de entrenamiento.\n",
    "    :type dataframe: pandas.Dataframe.\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    nc = 'numberOfClasses'\n",
    "    len_training_instances = 'N'\n",
    "    \n",
    "    # El diccionario donde se almacenan las frecuencias \n",
    "    # y que se guarda en un JSON al final de la función\n",
    "    \n",
    "    frequency = dict()\n",
    "    frequency[len_training_instances] = len(dataframe)\n",
    "    \n",
    "    # Por cada atributo objetivo (etiqueta) contamos frecuencias\n",
    "    for label in labels:\n",
    "        \n",
    "        freq_label = dataframe[label].value_counts()\n",
    "        \n",
    "        # Si la etiqueta no está en el diccionario la agregamos y \n",
    "        # además añadimos el número de clases distintas\n",
    "        if not label in frequency:\n",
    "            frequency[label] = dict()\n",
    "            frequency[label][nc] = len(dataframe[label].unique())\n",
    "        # Iteramos sobre todos los posibles valores de la clase y sus \n",
    "        # frecuencias\n",
    "        for label_val, freq in freq_label.iteritems():\n",
    "            # Guardamos en el diccionarios los nombres de las clases de nuestra etiqueta y\n",
    "            # sus frecuencias\n",
    "            frequency[label][label_val] = freq\n",
    "        \n",
    "        # Iteramos sobre todas las instancias de entrenamiento.\n",
    "        for attribute in dataframe:\n",
    "            if attribute == label:\n",
    "                continue\n",
    "            # Si no existe el atributo en nuestro diccionario de frecuencias.\n",
    "            if not attribute in frequency:\n",
    "                frequency[attribute] = dict()\n",
    "                # El número de valores distintos que puede tomar el atributo\n",
    "                frequency[attribute][nc] =len(dataframe[attribute].unique())\n",
    "                \n",
    "                # Por cada valor distinto que puede tomar el atributo,\n",
    "                # sacamos la frecuencia.\n",
    "                freq_attr = dataframe[attribute].value_counts()\n",
    "                for att_val, freq in freq_attr.iteritems():\n",
    "                    frequency[attribute][att_val] = freq\n",
    "            \n",
    "            # Calculas las frecuencias por cada valor que toma el atributo \n",
    "            # y cada valor que puede tomar la etiqueta. Esto es X_i = x_i AND C = c\n",
    "            frequency[attribute][label] = dict()\n",
    "            freq_attr_and_label_series = dataframe.groupby(attribute)[label].value_counts()\n",
    "            for index, value in freq_attr_and_label_series.iteritems():\n",
    "                attr_value = index[0]\n",
    "                label_value = index[1]\n",
    "                frequency[attribute][label][attr_value] = dict()\n",
    "                frequency[attribute][label][attr_value][label_value] = value\n",
    "\n",
    "    # Guardo el diccionario como un JSON.\n",
    "    with open(output_file, 'w') as outfile:\n",
    "        json.dump(frequency, outfile)\n",
    "\n",
    "\n",
    "def apply_bayes(label, dataframe, input_file=\"freqs.json\", k=1, m=2):\n",
    "    \"\"\"\n",
    "    Aplica Naive Bayes a un conjunto de prueba en un dataframe de pandas.\n",
    "    \n",
    "    \n",
    "    \"\"\"\n",
    "    pred_labels = []\n",
    "    key_nc = 'numberOfClasses'\n",
    "    \n",
    "    # Obtiene un objeto con los valores de la clase.\n",
    "    y = dataframe[label].unique()\n",
    "    \n",
    "    # Abre el archivo con las frecuencias del conjunto de entrenamiento.\n",
    "    with open(input_file, 'r') as f:\n",
    "        freq = json.loads(f.read())\n",
    "    \n",
    "    # Define el N, el número de instancias.\n",
    "    N = freq['N']\n",
    "    \n",
    "    \n",
    "    # Se itera sobre cada instancia de prueba.\n",
    "    for _, row in dataframe.iterrows():\n",
    "        \n",
    "        # Se incializa la variable que guarda la etiqueta de la instancia.\n",
    "        row_label = None\n",
    "        max_prob = -10E10\n",
    "        \n",
    "        # Por cada valor posible de la clase u etiqueta.\n",
    "        for y_hat in y:\n",
    "            #cast_y_hat = y_hat.decode('ASCII') if type(y_hat) is bytes else y_hat\n",
    "            \n",
    "            # nc = # de instancias que satisfacen C = c\n",
    "            nc = freq[label].get(y_hat, 0)\n",
    "            \n",
    "            # n  = # de clases\n",
    "            n = freq[label][key_nc]\n",
    "            \n",
    "            # Calculamos P(C=c) usando Laplace-estimate\n",
    "            p_c_laplace_estimator = (nc + k) / (N + n * k)\n",
    "            ans = p_c_laplace_estimator\n",
    "            \n",
    "            #print(\"P({}={}) = {}\".format(label, cast_y_hat, ans))\n",
    "            # Iteramos sobre cada atributo de la instancia para\n",
    "            # calcular P(Xi=xi | C=c) usando M-estimate\n",
    "            for attr, x_i in row.iteritems():\n",
    "                if attr == label:\n",
    "                    continue\n",
    "                p_xi_laplace_estimator = 0\n",
    "                \n",
    "                # Obtenemos el # de instancias que satisfacen Xi = xi\n",
    "                n_xi = freq[attr].get(x_i, 0)\n",
    "                \n",
    "                # Obtenemos el # de valores posibles que toma Xi\n",
    "                n = freq[attr][key_nc]\n",
    "                \n",
    "                #print(\"({} + {}) / ({} + {} * {})\".format(n_xi, k, N, n, k))\n",
    "                \n",
    "                # Calculamos P(Xi=xi) usando Laplace-estimate\n",
    "                p_xi_laplace_estimator = (n_xi + k) / (N + n * k)\n",
    "                nci = 0\n",
    "                #print(\"P({}={}) = {}\".format(attr, x_i, p_xi_laplace_estimator))\n",
    "                \n",
    "                # Obtenemos el número de instancias que satisdacen Xi = xi y C = c\n",
    "                if x_i in freq[attr][label] and y_hat in freq[attr][label][x_i]:\n",
    "                    nci = freq[attr][label][x_i][y_hat]\n",
    "                #print(\"({} + {} * {}) / ({} + {})\".format(nci, m, p_xi_laplace_estimator, nc, m))\n",
    "                \n",
    "                # Calculamos P(Xi=xi | C=c) usando M-estimate\n",
    "                m_estimator_xi_given_c = (nci + m * p_xi_laplace_estimator) / (nc + m)\n",
    "                \n",
    "                #print(\"P({}={}|{}={}) = {}\".format(attr, x_i, label, cast_y_hat, m_estimator_xi_given_c))\n",
    "                \n",
    "                # Hacemos el producto de la probabilidades\n",
    "                ans *= m_estimator_xi_given_c\n",
    "            # Cambio la etiqueta si la probabilidad es mayor para este valor de la \n",
    "            # etiqueta.\n",
    "            if ans > max_prob:\n",
    "                row_label = y_hat\n",
    "                max_prob = ans\n",
    "        # Agrego a mi vector de etiquetas inferida\n",
    "#         pred_labels.append(\"b'0'\" if row_label == \"b'1'\" else \"b'1'\")\n",
    "        pred_labels.append(row_label)\n",
    "    \n",
    "    pred_labels = np.array(pred_labels)\n",
    "    correct_labels = dataframe[label]\n",
    "    print(\"Accuracy Score = {}\".format(accuracy_score(correct_labels, pred_labels)))\n",
    "    #print(\"Accuracy Score Not Normalized = {}\".format(accuracy_score(correct_labels, pred_labels, normalize=False)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import KBinsDiscretizer\n",
    "# train_df_flags['area'] = pd.qcut(train_df_flags['area'], 5, labels=False)\n",
    "for attr in train_df_flags:\n",
    "    if train_df_flags[attr].dtype != 'object':\n",
    "        train_df_flags[attr] = pd.cut(train_df_flags[attr], 10, labels=False)\n",
    "        test_df_flags[attr] = pd.cut(test_df_flags[attr], 10, labels=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "labels = ['red','green','blue','yellow','white','black','orange']\n",
    "# train_df_flags = proportional_k_interval_discretization(train_df_flags)\n",
    "# test_df_flags = proportional_k_interval_discretization(test_df_flags)\n",
    "train_df_flags = train_df_flags[train_df_flags.columns[:]].apply(le.fit_transform)\n",
    "test_df_flags = test_df_flags[test_df_flags.columns[:]].apply(le.fit_transform)\n",
    "train_bayes_freq(labels, train_df_flags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score = 0.7538461538461538\n",
      "Accuracy Score = 0.5846153846153846\n",
      "Accuracy Score = 0.49230769230769234\n",
      "Accuracy Score = 0.46153846153846156\n",
      "Accuracy Score = 0.7846153846153846\n",
      "Accuracy Score = 0.3230769230769231\n",
      "Accuracy Score = 0.9076923076923077\n"
     ]
    }
   ],
   "source": [
    "for lab in labels:\n",
    "    apply_bayes(lab, test_df_flags)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score = 0.49230769230769234\n",
      "Accuracy score = 0.49230769230769234\n",
      "Accuracy score = 0.676923076923077\n",
      "Accuracy score = 0.6307692307692307\n",
      "Accuracy score = 0.4153846153846154\n",
      "Accuracy score = 0.6923076923076923\n",
      "Accuracy score = 0.7846153846153846\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "for label in labels:\n",
    "    X = train_df_flags.drop(label, axis=1)\n",
    "    y = train_df_flags[label]\n",
    "    X  = proportional_k_interval_discretization(X)\n",
    "    \n",
    "    clf = MultinomialNB()\n",
    "    le = LabelEncoder()\n",
    "    X = X[X.columns[:]].apply(le.fit_transform)\n",
    "    Y = pd.to_numeric(y, downcast='signed')\n",
    "    clf.fit(X, Y)\n",
    "    X_test = test_df_flags.drop(label, axis=1)\n",
    "    X_test = X_test[X_test.columns[:]].apply(le.fit_transform)\n",
    "    Y_test = pd.to_numeric(test_df_flags[label], downcast='signed')\n",
    "    y_pred = clf.predict(X_test)\n",
    "    print(\"Accuracy score = {}\".format(accuracy_score(Y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = ['amazed-suprised', 'happy-pleased', 'relaxing-calm', 'quiet-still', 'sad-lonely', 'angry-aggresive']\n",
    "#train_df_emo = proportional_k_interval_discretization(train_df_emo)\n",
    "#test_df_emo = proportional_k_interval_discretization(test_df_emo)\n",
    "train_bayes_freq(labels, train_df_emo, 'train_emo_freq.json')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score = 0.7326732673267327\n",
      "Accuracy Score Not Normalized = 148\n",
      "Accuracy Score = 0.7079207920792079\n",
      "Accuracy Score Not Normalized = 143\n",
      "Accuracy Score = 0.5247524752475248\n",
      "Accuracy Score Not Normalized = 106\n",
      "Accuracy Score = 0.7079207920792079\n",
      "Accuracy Score Not Normalized = 143\n",
      "Accuracy Score = 0.6386138613861386\n",
      "Accuracy Score Not Normalized = 129\n",
      "Accuracy Score = 0.7128712871287128\n",
      "Accuracy Score Not Normalized = 144\n"
     ]
    }
   ],
   "source": [
    "for lab in labels:\n",
    "    apply_bayes(lab, test_df_emo, 'train_emo_freq.json')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Gender</th>\n",
       "      <th>Height</th>\n",
       "      <th>Weight</th>\n",
       "      <th>Foot_Size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>female</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>female</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>female</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>female</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>male</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>male</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>male</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>male</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Gender  Height  Weight  Foot_Size\n",
       "4  female     0.0       0          0\n",
       "6  female     0.0       0          0\n",
       "5  female     1.0       1          1\n",
       "7  female     1.0       1          1\n",
       "3    male     1.0       1          1\n",
       "1    male     1.0       1          1\n",
       "2    male     1.0       1          1\n",
       "0    male     1.0       1          1"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.DataFrame()\n",
    "\n",
    "# Create our target variable\n",
    "data['Gender'] = ['male','male','male','male','female','female','female','female']\n",
    "\n",
    "# Create our feature variables\n",
    "data['Height'] = [6,5.92,5.58,5.92,5,5.5,5.42,5.75]\n",
    "data['Weight'] = [180,190,170,165,100,150,130,150]\n",
    "data['Foot_Size'] = [12,11,12,10,6,8,7,9]\n",
    "\n",
    "# View the data\n",
    "data_discrete = proportional_k_interval_discretization(data)\n",
    "data_discrete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      male\n",
       "1      male\n",
       "2      male\n",
       "3      male\n",
       "4    female\n",
       "5    female\n",
       "6    female\n",
       "7    female\n",
       "Name: Gender, dtype: object"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['Gender']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_bayes_freq(['Gender'], data_discrete, output_file=\"sex\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "person = pd.DataFrame()\n",
    "\n",
    "# Create some feature values for this single row\n",
    "person['Gender'] = 'female'\n",
    "person['Height'] = [6]\n",
    "person['Weight'] = [130]\n",
    "person['Foot_Size'] = [8]\n",
    "\n",
    "# View the data \n",
    "person = proportional_k_interval_discretization(person)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score = 0.0\n",
      "Accuracy Score Not Normalized = 0\n"
     ]
    }
   ],
   "source": [
    "apply_bayes('Gender', person, \"sex\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
